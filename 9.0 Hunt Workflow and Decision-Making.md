## 9.1 Explain a standard triage flow (mount -> identify users -> establish timeframe -> persistence -> execution -> network -> malware triage)

- Step 1: Mount evidence read-only
  - Mount the disk image read-only (or effectively read-only) and confirm volume access.
  - Create a clean case workspace: `evidence/`, `work/`, `exports/`, `logs/`, `hashes/`, `notes/`.
  - Record mount details (tool, mode, drive letters, errors).
- Step 2: Identify users and high-value profiles
  - Enumerate user profiles and identify likely primary users and admin accounts.
  - Prioritize accounts with interactive logons, admin rights, and recent activity.
  - Identify likely staging locations (Downloads, Desktop, AppData, Temp).
- Step 3: Establish the timeframe (anchor your story)
  - Determine suspected intrusion window from known events (alert time, user report, outage).
  - Pull key timestamps: first suspicious file write, first auth anomaly, first persistence artifact.
  - Normalize everything to UTC in notes to prevent time zone drift.
- Step 4: Hunt persistence (how it survives reboot)
  - Check services, scheduled tasks, Run keys, startup folders, WMI subscriptions.
  - Look for odd paths, renamed binaries, LOLBins, and new entries near the timeframe.
  - Promote persistence items to high priority because they provide repeatable evidence.
- Step 5: Hunt execution (what actually ran)
  - Tie suspicious artifacts to execution indicators: process creation logs, prefetch (if enabled), user artifacts.
  - Capture command lines, parent-child process relationships, and binary paths.
  - Separate "present on disk" from "executed" as different claims.
- Step 6: Hunt network context (what it talked to)
  - Correlate any outbound connections or DNS indicators to owning processes/users.
  - Prioritize rare ports, unusual destinations, and processes that should not reach out.
  - Treat network indicators as supporting context unless corroborated.
- Step 7: Malware triage and packaging
  - Use entropy, YARA, and signature checks to prioritize suspicious binaries.
  - Export only what you can justify, hash everything, and preserve paths/context.
  - Prepare a minimal handoff package for deeper analysis when required.

## 9.2 Define "lead" vs "evidence" and apply confidence language (low/medium/high based on corroboration)
- Definitions that prevent team confusion
  - Lead: a clue that suggests a direction but is not yet supported by multiple independent sources.
  - Evidence: a claim supported by corroboration that can withstand challenge.
- Confidence language (use consistently)
  - Low confidence
    - Single-source indicator with no corroboration.
    - Examples: one YARA hit, one high-entropy file, one suspicious filename.
  - Medium confidence
    - Two sources agree or one source is strong plus supporting context.
    - Examples: YARA hit + suspicious location, unsigned binary + abnormal path + matching timeframe.
  - High confidence
    - Multiple independent artifacts support the same conclusion.
    - Examples: persistence entry points to a binary, execution artifacts show it ran, and logs show related network activity.
- Rule for upgrading confidence
  - Increase confidence only when you add independent corroboration.
  - Do not upgrade confidence based on repeating the same weak indicator in multiple places.

## 9.3 Differentiate commodity malware vs intrusion tradecraft indicators (basic patterns, not attribution)
- Commodity malware patterns (common, noisy, scalable)
  - Common distribution and staging: email attachments, downloads, common droppers.
  - Simple persistence: Run keys, obvious scheduled tasks, straightforward service installs.
  - Broad targeting and opportunism: many victims, generic tooling, repeatable behaviors.
  - Tooling signatures often show up in public rule sets and reputation sources.
- Intrusion tradecraft indicators (more deliberate, lower noise)
  - Living-off-the-land execution (LOLBins) used to blend in with normal admin activity.
  - Minimal footprint and selective actions (limited file drops, careful timing).
  - Credential access and privilege escalation patterns rather than just "drop and run."
  - Persistence designed to look legitimate (plausible service/task names, plausible paths).
  - Operational security behavior (cleanup, log tampering attempts, staging in obscure directories).
- Boundaries to enforce in reporting
  - Describe observed behaviors, not assumed actor identity.
  - Avoid attribution language unless you have explicit policy and strong evidence.
  - Focus on: initial access indicators, persistence mechanism, execution chain, and impact.